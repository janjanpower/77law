#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºæ…§Excelåˆ†æå™¨ - ğŸ”¥ å®Œæ•´ç‰ˆæœ¬
è‡ªå‹•è­˜åˆ¥å·¥ä½œè¡¨ã€æ¨™é¡Œåˆ—å’Œæ¬„ä½å°æ‡‰ï¼Œæ”¯æ´æ™ºæ…§åˆä½µå’Œéˆæ´»åŒ¹é…
å®Œæ•´å¯¦ç¾æ‰€æœ‰åˆ†æå’Œè³‡æ–™æå–åŠŸèƒ½
"""
import os
from typing import Dict, List, Optional, Tuple, Any
from utils.data_cleaner import DataCleaner

# Excelè™•ç†ç›¸é—œä¾è³´
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    import openpyxl
    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False

try:
    import xlrd
    XLRD_AVAILABLE = True
except ImportError:
    XLRD_AVAILABLE = False

# å˜—è©¦å°å…¥CaseDataæ¨¡å‹
try:
    from models.case_model import CaseData
    CASE_MODEL_AVAILABLE = True
except ImportError:
    CASE_MODEL_AVAILABLE = False
    print("âš ï¸ CaseData æ¨¡å‹ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨å­—å…¸æ ¼å¼")


class SmartExcelAnalyzer:
    """æ™ºæ…§Excelåˆ†æå™¨ - ğŸ”¥ å®Œæ•´ç‰ˆæœ¬"""

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # ğŸ”¥ æ¬„ä½é—œéµå­—å°æ‡‰è¡¨ - æ ¹æ“šéœ€æ±‚è¨­è¨ˆ
        self.field_keywords = {
            'case_id': ['ç·¨è™Ÿ', 'æ¡ˆä»¶ç·¨è™Ÿ', 'ID', 'id', 'åºè™Ÿ', 'æµæ°´è™Ÿ', 'æ¡ˆä»¶ID', 'æ¡ˆä»¶id'],
            'case_reason': ['æ¡ˆç”±', 'äº‹ç”±', 'æ¡ˆä»¶äº‹ç”±', 'è¨´è¨Ÿäº‹ç”±', 'æ¡ˆä»¶åŸå› ', 'äº‹ä»¶é¡å‹', 'äº‹ä»¶', 'åŸå› '],
            'case_number': ['æ¡ˆè™Ÿ', 'æ©Ÿé—œ', 'æ¡ˆä»¶è™Ÿç¢¼', 'æ©Ÿé—œæ¡ˆè™Ÿ', 'æ³•é™¢æ¡ˆè™Ÿ', 'æ¡ˆä»¶è™Ÿ', 'è™Ÿç¢¼'],  # ğŸ”¥ æ–°å¢ case_number
            'court': ['æ³•é™¢', 'è² è²¬æ³•é™¢', 'ç®¡è½„æ³•é™¢', 'å¯©ç†æ³•é™¢', 'æ³•åº­'],  # ğŸ”¥ ä¿®æ”¹ court æ¬„ä½é—œéµå­—
            'client': ['ç•¶äº‹äºº', 'å®¢æˆ¶', 'å®¢æˆ¶åç¨±', 'å§“å', 'å§”è¨—äºº', 'ç”³è«‹äºº', 'ç•¶äº‹è€…', 'åç¨±'],
            'lawyer': ['å§”ä»»å¾‹å¸«', 'å¾‹å¸«', 'ä»£ç†å¾‹å¸«', 'è¾¯è­·å¾‹å¸«', 'è¨´è¨Ÿä»£ç†äºº', 'ä»£è¡¨å¾‹å¸«', 'å¾‹å¸«å§“å'],
            'legal_affairs': ['æ³•å‹™', 'æ³•å‹™äººå“¡', 'åŠ©ç†', 'æ³•å‹™åŠ©ç†', 'æ‰¿è¾¦äºº', 'è² è²¬äºº', 'ç¶“è¾¦äºº'],
            'opposing_party': ['å°é€ ', 'ç›¸å°äºº', 'è¢«å‘Š', 'å°æ–¹ç•¶äº‹äºº', 'å¦ä¸€æ–¹', 'å°æ–¹'],
            'division': ['è‚¡åˆ¥', 'åˆ†æ©Ÿ']
        }

        # ğŸ”¥ æ¡ˆä»¶é¡å‹é—œéµå­—
        self.case_type_keywords = {
            'æ°‘äº‹': ['æ°‘äº‹', 'æ°‘å•†', 'æ°‘', 'civil', 'Civil', 'CIVIL'],
            'åˆ‘äº‹': ['åˆ‘äº‹', 'åˆ‘', 'criminal', 'Criminal', 'CRIMINAL']
        }

        # ğŸ”¥ æ¨™é¡Œåˆ—è­˜åˆ¥çš„æœ€å°å¾—åˆ†é–¾å€¼
        self.header_min_score = 2

        # ğŸ”¥ åˆä½µæ¬„ä½çš„åˆ†éš”ç¬¦
        self.merge_separator = '-'

    def analyze_excel_comprehensive(self, file_path: str) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ğŸ”¥ å…¨é¢åˆ†æExcelæª”æ¡ˆ

        Args:
            file_path: Excelæª”æ¡ˆè·¯å¾‘

        Returns:
            Tuple[bool, str, Dict]: (æˆåŠŸç‹€æ…‹, è©³ç´°åˆ†æçµæœ, çµæ§‹åŒ–è³‡æ–™)
        """
        try:
            print(f"ğŸ” é–‹å§‹åˆ†æExcelæª”æ¡ˆ: {file_path}")

            if not PANDAS_AVAILABLE:
                return False, "pandas ä¸å¯ç”¨ï¼Œç„¡æ³•åˆ†æ Excel", {}

            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return False, f"æª”æ¡ˆä¸å­˜åœ¨: {file_path}", {}

            # ç¬¬1æ­¥ï¼šå–å¾—æ‰€æœ‰å·¥ä½œè¡¨
            print("ğŸ“‹ æ­¥é©Ÿ1: è®€å–å·¥ä½œè¡¨...")
            sheets_info = self._get_all_sheets(file_path)
            if not sheets_info['success']:
                return False, sheets_info['message'], {}

            print(f"âœ… æ‰¾åˆ° {sheets_info['total_sheets']} å€‹å·¥ä½œè¡¨")

            # ç¬¬2æ­¥ï¼šåˆ†ææ¯å€‹å·¥ä½œè¡¨çš„æ¡ˆä»¶é¡å‹
            print("ğŸ·ï¸ æ­¥é©Ÿ2: åˆ†é¡å·¥ä½œè¡¨...")
            categorized_sheets = self._categorize_sheets_by_case_type(sheets_info['sheets'])

            civil_count = len(categorized_sheets['æ°‘äº‹'])
            criminal_count = len(categorized_sheets['åˆ‘äº‹'])
            unknown_count = len(categorized_sheets['unknown'])

            print(f"âœ… åˆ†é¡å®Œæˆ: æ°‘äº‹{civil_count}å€‹, åˆ‘äº‹{criminal_count}å€‹, æœªè­˜åˆ¥{unknown_count}å€‹")

            # ç¬¬3æ­¥ï¼šåˆ†ææ¯å€‹ç›¸é—œå·¥ä½œè¡¨çš„æ¬„ä½çµæ§‹
            print("ğŸ” æ­¥é©Ÿ3: åˆ†ææ¬„ä½çµæ§‹...")
            sheets_analysis = {}
            total_analyzed = 0

            for case_type, sheet_names in categorized_sheets.items():
                if case_type in ['æ°‘äº‹', 'åˆ‘äº‹'] and sheet_names:
                    for sheet_name in sheet_names:
                        print(f"  åˆ†æå·¥ä½œè¡¨: {sheet_name}")
                        analysis = self._analyze_sheet_structure(file_path, sheet_name, case_type)
                        if analysis['success']:
                            sheets_analysis[sheet_name] = analysis
                            total_analyzed += 1
                            print(f"  âœ… {sheet_name}: æ‰¾åˆ°{analysis['required_fields_found']}å€‹æ¬„ä½, {analysis['data_rows']}è¡Œè³‡æ–™")
                        else:
                            print(f"  âŒ {sheet_name}: {analysis['message']}")

            print(f"âœ… çµæ§‹åˆ†æå®Œæˆ: {total_analyzed}å€‹å·¥ä½œè¡¨å¯è™•ç†")

            # ç¬¬4æ­¥ï¼šç”Ÿæˆåˆ†æå ±å‘Š
            print("ğŸ“Š æ­¥é©Ÿ4: ç”Ÿæˆåˆ†æå ±å‘Š...")
            analysis_report = self._generate_analysis_report(categorized_sheets, sheets_analysis)

            result = {
                'categorized_sheets': categorized_sheets,
                'sheets_analysis': sheets_analysis,
                'total_processable_sheets': len(sheets_analysis),
                'analysis_report': analysis_report,
                'file_path': file_path,
                'engine': sheets_info.get('engine', 'auto')
            }

            print("âœ… åˆ†æå®Œæˆ!")
            return True, analysis_report, result

        except Exception as e:
            error_msg = f"åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return False, error_msg, {}

    def _get_all_sheets(self, file_path: str) -> Dict[str, Any]:
        """å–å¾—Excelæª”æ¡ˆä¸­çš„æ‰€æœ‰å·¥ä½œè¡¨"""
        try:
            engine = self._get_best_engine(file_path)
            if not engine:
                return {'success': False, 'message': 'ç„¡å¯ç”¨çš„Excelè®€å–å¼•æ“'}

            print(f"  ä½¿ç”¨å¼•æ“: {engine}")

            if engine == 'openpyxl':
                excel_file = pd.ExcelFile(file_path, engine='openpyxl')
            elif engine == 'xlrd':
                excel_file = pd.ExcelFile(file_path, engine='xlrd')
            else:
                excel_file = pd.ExcelFile(file_path)

            sheets = excel_file.sheet_names
            if not sheets:
                return {'success': False, 'message': 'Excelæª”æ¡ˆä¸­æ²’æœ‰å·¥ä½œè¡¨'}

            return {
                'success': True,
                'sheets': sheets,
                'total_sheets': len(sheets),
                'engine': engine
            }

        except Exception as e:
            return {'success': False, 'message': f'è®€å–Excelæª”æ¡ˆå¤±æ•—ï¼š{str(e)}'}

    def _categorize_sheets_by_case_type(self, sheet_names: List[str]) -> Dict[str, List[str]]:
        """ğŸ”¥ æ ¹æ“šæ¡ˆä»¶é¡å‹åˆ†é¡å·¥ä½œè¡¨"""
        categorized = {
            'æ°‘äº‹': [],
            'åˆ‘äº‹': [],
            'unknown': []
        }

        for sheet_name in sheet_names:
            classified = False
            sheet_name_clean = str(sheet_name).strip()

            # æª¢æŸ¥æ°‘äº‹é—œéµå­—
            for keyword in self.case_type_keywords['æ°‘äº‹']:
                if keyword in sheet_name_clean:
                    categorized['æ°‘äº‹'].append(sheet_name)
                    classified = True
                    print(f"  ğŸ“ {sheet_name} â†’ æ°‘äº‹ (åŒ¹é…: {keyword})")
                    break

            # å¦‚æœé‚„æ²’åˆ†é¡ï¼Œæª¢æŸ¥åˆ‘äº‹é—œéµå­—
            if not classified:
                for keyword in self.case_type_keywords['åˆ‘äº‹']:
                    if keyword in sheet_name_clean:
                        categorized['åˆ‘äº‹'].append(sheet_name)
                        classified = True
                        print(f"  âš–ï¸ {sheet_name} â†’ åˆ‘äº‹ (åŒ¹é…: {keyword})")
                        break

            # å¦‚æœéƒ½æ²’åŒ¹é…ï¼Œæ­¸é¡ç‚ºæœªçŸ¥
            if not classified:
                categorized['unknown'].append(sheet_name)
                print(f"  â“ {sheet_name} â†’ æœªè­˜åˆ¥")

        return categorized

    def _analyze_sheet_structure(self, file_path: str, sheet_name: str, case_type: str) -> Dict[str, Any]:
        """ğŸ”¥ åˆ†æå–®ä¸€å·¥ä½œè¡¨çš„çµæ§‹"""
        try:
            engine = self._get_best_engine(file_path)

            # å…ˆè®€å–å·¥ä½œè¡¨çš„å‰å¹¾è¡Œä¾†å°‹æ‰¾æ¨™é¡Œåˆ—
            print(f"    è®€å–å·¥ä½œè¡¨: {sheet_name}")
            if engine == 'openpyxl':
                df_preview = pd.read_excel(file_path, sheet_name=sheet_name,
                                         engine='openpyxl', nrows=15, header=None)
            elif engine == 'xlrd':
                df_preview = pd.read_excel(file_path, sheet_name=sheet_name,
                                         engine='xlrd', nrows=15, header=None)
            else:
                df_preview = pd.read_excel(file_path, sheet_name=sheet_name,
                                         nrows=15, header=None)

            if df_preview.empty:
                return {'success': False, 'message': f'å·¥ä½œè¡¨ {sheet_name} æ˜¯ç©ºçš„'}

            # ğŸ”¥ æ™ºæ…§å°‹æ‰¾æ¨™é¡Œåˆ—
            print(f"    å°‹æ‰¾æ¨™é¡Œåˆ—...")
            header_row = self._find_header_row(df_preview)
            if header_row is None:
                return {'success': False, 'message': f'å·¥ä½œè¡¨ {sheet_name} æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—'}

            print(f"    æ¨™é¡Œåˆ—ä½ç½®: ç¬¬ {header_row + 1} è¡Œ")

            # ä½¿ç”¨æ‰¾åˆ°çš„æ¨™é¡Œåˆ—é‡æ–°è®€å–å®Œæ•´è³‡æ–™
            if engine == 'openpyxl':
                df = pd.read_excel(file_path, sheet_name=sheet_name,
                                 header=header_row, engine='openpyxl')
            elif engine == 'xlrd':
                df = pd.read_excel(file_path, sheet_name=sheet_name,
                                 header=header_row, engine='xlrd')
            else:
                df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)

            # ğŸ”¥ æ™ºæ…§æ¬„ä½å°æ‡‰
            print(f"    åˆ†ææ¬„ä½å°æ‡‰...")
            column_mapping = self._smart_column_mapping(df.columns.tolist())

            # çµ±è¨ˆæ‰¾åˆ°çš„æ¬„ä½
            found_fields = sum(1 for v in column_mapping.values() if v is not None)
            print(f"    æ‰¾åˆ°æ¬„ä½: {found_fields}/{len(self.field_keywords)}")

            # ğŸ”¥ æª¢æŸ¥åˆä½µæ¬„ä½éœ€æ±‚ (æ¡ˆè™Ÿç›¸é—œ)
            merge_info = self._check_merge_requirements(df.columns.tolist())
            if merge_info['needs_merge']:
                print(f"    éœ€è¦åˆä½µæ¬„ä½: {', '.join(merge_info['case_number_fields'])}")

            # çµ±è¨ˆè³‡æ–™è¡Œæ•¸
            data_rows = len(df.dropna(how='all'))  # æ’é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
            print(f"    è³‡æ–™è¡Œæ•¸: {data_rows}")

            return {
                'success': True,
                'case_type': case_type,
                'header_row': header_row,
                'column_mapping': column_mapping,
                'merge_info': merge_info,
                'total_columns': len(df.columns),
                'data_rows': data_rows,
                'columns': df.columns.tolist(),
                'required_fields_found': found_fields,
                'has_client_field': column_mapping.get('client') is not None,
                'sample_data': df.head(3).to_dict('records') if data_rows > 0 else []  # ä¿å­˜æ¨£æœ¬è³‡æ–™
            }

        except Exception as e:
            return {'success': False, 'message': f'åˆ†æå·¥ä½œè¡¨ {sheet_name} å¤±æ•—ï¼š{str(e)}'}

    def _find_header_row(self, df: pd.DataFrame) -> Optional[int]:
        """ğŸ”¥ æ™ºæ…§å°‹æ‰¾æ¨™é¡Œåˆ—ä½ç½®"""
        max_rows_to_check = min(10, len(df))

        best_row = 0
        best_score = 0

        print(f"      æª¢æŸ¥å‰ {max_rows_to_check} è¡Œ...")

        for row_idx in range(max_rows_to_check):
            score = 0
            matched_keywords = []

            if row_idx >= len(df):
                break

            row_data = df.iloc[row_idx]

            # è¨ˆç®—è©²è¡ŒåŒ…å«å¤šå°‘å€‹å¯èƒ½çš„æ¬„ä½é—œéµå­—
            for cell_value in row_data:
                if pd.notna(cell_value):
                    cell_text = str(cell_value).strip()

                    # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•æ¬„ä½é—œéµå­—
                    for field_name, field_keywords in self.field_keywords.items():
                        for keyword in field_keywords:
                            if keyword in cell_text:
                                score += 1
                                matched_keywords.append(f"{keyword}({field_name})")
                                break  # æ‰¾åˆ°ä¸€å€‹å°±è·³å‡º

            print(f"      ç¬¬ {row_idx + 1} è¡Œ: å¾—åˆ† {score}, åŒ¹é…: {', '.join(matched_keywords[:3])}")

            # å¦‚æœé€™ä¸€è¡Œçš„å¾—åˆ†æ›´é«˜ï¼Œæ›´æ–°æœ€ä½³æ¨™é¡Œåˆ—
            if score > best_score:
                best_score = score
                best_row = row_idx

        # å¦‚æœå¾—åˆ†å¤ªä½ï¼Œå¯èƒ½æ²’æœ‰æ‰¾åˆ°åˆé©çš„æ¨™é¡Œåˆ—
        if best_score < self.header_min_score:
            print(f"      âŒ æœ€é«˜å¾—åˆ† {best_score} ä½æ–¼é–¾å€¼ {self.header_min_score}")
            return None

        print(f"      âœ… é¸æ“‡ç¬¬ {best_row + 1} è¡Œ (å¾—åˆ†: {best_score})")
        return best_row

    def _smart_column_mapping(self, columns: List[str]) -> Dict[str, Optional[str]]:
        """ğŸ”¥ æ™ºæ…§æ¬„ä½å°æ‡‰"""
        mapping = {field: None for field in self.field_keywords.keys()}

        print(f"      å¯ç”¨æ¬„ä½: {', '.join(str(col) for col in columns)}")

        for field, keywords in self.field_keywords.items():
            best_match = None
            best_score = 0

            for col in columns:
                if pd.notna(col):
                    col_text = str(col).strip()

                    # è¨ˆç®—åŒ¹é…å¾—åˆ†
                    score = 0
                    matched_keyword = None

                    for keyword in keywords:
                        if keyword in col_text:
                            # å®Œå…¨åŒ¹é…å¾—åˆ†æ›´é«˜
                            if keyword == col_text:
                                score += 10
                                matched_keyword = keyword
                            else:
                                score += 1
                                if not matched_keyword:  # è¨˜éŒ„ç¬¬ä¸€å€‹åŒ¹é…çš„é—œéµå­—
                                    matched_keyword = keyword

                    if score > best_score:
                        best_score = score
                        best_match = col

            if best_match:
                mapping[field] = best_match
                print(f"      âœ… {self._get_field_display_name(field)}: ã€Œ{best_match}ã€")
            else:
                print(f"      âŒ {self._get_field_display_name(field)}: æœªæ‰¾åˆ°")

        return mapping

    def _check_merge_requirements(self, columns: List[str]) -> Dict[str, Any]:
        """ğŸ”¥ æª¢æŸ¥éœ€è¦åˆä½µçš„æ¬„ä½ï¼ˆä¸»è¦é‡å°æ¡ˆè™Ÿç›¸é—œï¼‰"""
        merge_info = {
            'case_number_fields': [],
            'needs_merge': False,
            'merge_separator': self.merge_separator
        }

        # ğŸ”¥ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„æ¡ˆè™Ÿé—œéµå­—
        case_number_keywords = self.field_keywords['case_number']  # åŸæœ¬æ˜¯ case_number

        for col in columns:
            if pd.notna(col):
                col_text = str(col).strip()
                for keyword in case_number_keywords:
                    if keyword in col_text:
                        merge_info['case_number_fields'].append(col)
                        break

        # å¦‚æœæ‰¾åˆ°å¤šå€‹æ¡ˆè™Ÿç›¸é—œæ¬„ä½ï¼Œæ¨™è¨˜éœ€è¦åˆä½µ
        if len(merge_info['case_number_fields']) > 1:
            merge_info['needs_merge'] = True

        return merge_info

    def _generate_analysis_report(self, categorized_sheets: Dict[str, List[str]],
                                 sheets_analysis: Dict[str, Dict]) -> str:
        """ğŸ”¥ ç”Ÿæˆè©³ç´°çš„åˆ†æå ±å‘Š"""
        lines = []

        # å·¥ä½œè¡¨åˆ†é¡çµ±è¨ˆ
        lines.append('ğŸ“‹ å·¥ä½œè¡¨åˆ†é¡çµæœï¼š')
        for case_type, sheets in categorized_sheets.items():
            if sheets:
                if case_type == 'æ°‘äº‹':
                    lines.append(f'  ğŸ“ æ°‘äº‹å·¥ä½œè¡¨ ({len(sheets)} å€‹)ï¼š')
                elif case_type == 'åˆ‘äº‹':
                    lines.append(f'  âš–ï¸ åˆ‘äº‹å·¥ä½œè¡¨ ({len(sheets)} å€‹)ï¼š')

        # è©³ç´°æ¬„ä½åˆ†æ
        if sheets_analysis:
            lines.append('')

            for sheet_name, analysis in sheets_analysis.items():
                lines.append(f'ğŸ“„ å·¥ä½œè¡¨ï¼š{sheet_name}')
                lines.append(f'   æ¡ˆä»¶é¡å‹ï¼š{analysis["case_type"]}')
                lines.append(f'   è³‡æ–™è¡Œæ•¸ï¼š{analysis["data_rows"]} è¡Œ')

        else:
            lines.append('âš ï¸ æ²’æœ‰æ‰¾åˆ°å¯è™•ç†çš„å·¥ä½œè¡¨')


        return '\n'.join(lines)

    def _get_field_display_name(self, field: str) -> str:
        """å–å¾—æ¬„ä½çš„é¡¯ç¤ºåç¨±"""
        display_names = {
            'case_id': 'æ¡ˆä»¶ç·¨è™Ÿ',
            'case_reason': 'æ¡ˆç”±',
            'case_number': 'æ¡ˆè™Ÿ',  # ğŸ”¥ æ–°å¢
            'court': 'æ³•é™¢',        # ğŸ”¥ ä¿®æ”¹é¡¯ç¤ºåç¨±
            'client': 'ç•¶äº‹äºº',
            'lawyer': 'å§”ä»»å¾‹å¸«',
            'legal_affairs': 'æ³•å‹™',
            'opposing_party': 'å°é€ ',
            'division': 'è‚¡åˆ¥'
        }
        return display_names.get(field, field)

    def extract_data_from_analysis(self, file_path: str, analysis_result: Dict[str, Any]) -> Tuple[bool, str, Dict[str, List]]:
        """ğŸ”¥ æ ¹æ“šåˆ†æçµæœæå–å¯¦éš›è³‡æ–™"""
        try:
            print(f"ğŸš€ é–‹å§‹æå–è³‡æ–™: {file_path}")

            all_cases = {'æ°‘äº‹': [], 'åˆ‘äº‹': []}
            import_summary = []

            sheets_analysis = analysis_result.get('sheets_analysis', {})

            if not sheets_analysis:
                return False, "æ²’æœ‰å¯ç”¨çš„å·¥ä½œè¡¨åˆ†æçµæœ", all_cases

            # ğŸ”¥ ä¿®æ­£ï¼šå„²å­˜åˆ†æçµæœä¾›å¾ŒçºŒä½¿ç”¨
            self._current_analysis_result = analysis_result

            for sheet_name, analysis in sheets_analysis.items():
                if not analysis.get('success', False):
                    continue

                if not analysis.get('has_client_field', False):
                    import_summary.append(f'ã€Œ{sheet_name}ã€: è·³é - ç¼ºå°‘ç•¶äº‹äººæ¬„ä½')
                    continue

                case_type = analysis['case_type']
                column_mapping = analysis['column_mapping']
                merge_info = analysis['merge_info']

                print(f"  è™•ç†å·¥ä½œè¡¨: {sheet_name} ({case_type})")
                print(f"    æ¬„ä½å°æ‡‰: {[(k, v) for k, v in column_mapping.items() if v]}")

                # å¾å·¥ä½œè¡¨æå–è³‡æ–™
                cases = self._extract_cases_from_sheet(
                    file_path, sheet_name, case_type, column_mapping, merge_info
                )

                if cases:
                    all_cases[case_type].extend(cases)
                    import_summary.append(f'ã€Œ{sheet_name}ã€: {len(cases)} ç­†{case_type}æ¡ˆä»¶')
                    print(f"    âœ… æå–äº† {len(cases)} ç­†è³‡æ–™")
                else:
                    import_summary.append(f'ã€Œ{sheet_name}ã€: æ²’æœ‰æœ‰æ•ˆè³‡æ–™')
                    print(f"    âŒ æ²’æœ‰æå–åˆ°æœ‰æ•ˆè³‡æ–™")

            # æ¸…ç†è‡¨æ™‚è®Šæ•¸
            if hasattr(self, '_current_analysis_result'):
                delattr(self, '_current_analysis_result')

            # çµ±è¨ˆçµæœ
            total_civil = len(all_cases['æ°‘äº‹'])
            total_criminal = len(all_cases['åˆ‘äº‹'])
            total_all = total_civil + total_criminal

            if total_all == 0:
                return False, "æ²’æœ‰æˆåŠŸæå–ä»»ä½•æ¡ˆä»¶è³‡æ–™", all_cases

            # ç”Ÿæˆçµæœè¨Šæ¯
            summary_msg = f"âœ… æ™ºæ…§åŒ¯å…¥å®Œæˆï¼å…± {total_all} ç­†æ¡ˆä»¶\n"
            if total_civil > 0:
                summary_msg += f"ğŸ“‹ æ°‘äº‹æ¡ˆä»¶: {total_civil} ç­†\n"
            if total_criminal > 0:
                summary_msg += f"âš–ï¸ åˆ‘äº‹æ¡ˆä»¶: {total_criminal} ç­†\n"

            summary_msg += "\nğŸ“Š è©³ç´°çµæœ:\n" + "\n".join(import_summary)

            print(f"âœ… è³‡æ–™æå–å®Œæˆ: å…± {total_all} ç­†")
            return True, summary_msg, all_cases

        except Exception as e:
            error_msg = f"è³‡æ–™æå–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return False, error_msg, {'æ°‘äº‹': [], 'åˆ‘äº‹': []}

    def _extract_cases_from_sheet(self, file_path: str, sheet_name: str, case_type: str,
                                 column_mapping: Dict[str, Optional[str]],
                                 merge_info: Dict[str, Any]) -> List:
        """å¾å–®ä¸€å·¥ä½œè¡¨æå–æ¡ˆä»¶è³‡æ–™"""
        try:
            engine = self._get_best_engine(file_path)

            # ğŸ”¥ ä¿®æ­£ï¼šéœ€è¦å¾åˆ†æçµæœä¸­å–å¾—æ­£ç¢ºçš„æ¨™é¡Œåˆ—ä½ç½®
            header_row = 0  # é è¨­å€¼

            # å¦‚æœæœ‰å„²å­˜çš„åˆ†æçµæœï¼Œä½¿ç”¨æ­£ç¢ºçš„æ¨™é¡Œåˆ—
            if hasattr(self, '_current_analysis_result'):
                for sheet_analysis in self._current_analysis_result.get('sheets_analysis', {}).values():
                    if sheet_analysis.get('case_type') == case_type:
                        header_row = sheet_analysis.get('header_row', 0)
                        break

            print(f"    ä½¿ç”¨æ¨™é¡Œåˆ—ä½ç½®: ç¬¬ {header_row + 1} è¡Œ")

            # ğŸ”¥ é—œéµä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„æ¨™é¡Œåˆ—ä½ç½®è®€å–è³‡æ–™
            if engine == 'openpyxl':
                df = pd.read_excel(file_path, sheet_name=sheet_name,
                                 header=header_row, engine='openpyxl')
            elif engine == 'xlrd':
                df = pd.read_excel(file_path, sheet_name=sheet_name,
                                 header=header_row, engine='xlrd')
            else:
                df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)

            if df.empty:
                print(f"    å·¥ä½œè¡¨ {sheet_name} è®€å–å¾Œç‚ºç©º")
                return []

            print(f"    å¯¦éš›è®€å–åˆ° {len(df)} è¡Œè³‡æ–™")
            print(f"    æ¬„ä½åç¨±: {list(df.columns)}")

            cases = []
            processed_rows = 0

            for index, row in df.iterrows():
                try:
                    # ğŸ”¥ æ™ºæ…§æå–å„æ¬„ä½è³‡æ–™ - ç¢ºä¿åŒ…å« court å’Œ case_number
                    case_data = {
                        'case_type': case_type,
                        'client': self._safe_extract_value(row, column_mapping.get('client')),
                        'case_id': self._safe_extract_value(row, column_mapping.get('case_id')),
                        'case_reason': self._safe_extract_value(row, column_mapping.get('case_reason')),
                        'lawyer': self._safe_extract_value(row, column_mapping.get('lawyer')),
                        'legal_affairs': self._safe_extract_value(row, column_mapping.get('legal_affairs')),
                        'opposing_party': self._safe_extract_value(row, column_mapping.get('opposing_party')),
                        'court': self._safe_extract_value(row, column_mapping.get('court')),  # ğŸ”¥ ç¢ºä¿æå– court
                        'division': self._safe_extract_value(row, column_mapping.get('division'))
                    }

                    # ğŸ”¥ è™•ç†æ¡ˆè™Ÿåˆä½µ
                    if merge_info['needs_merge']:
                        case_number_parts = []
                        for field in merge_info['case_number_fields']:
                            part = self._safe_extract_value(row, field)
                            if part:
                                case_number_parts.append(part)
                        case_data['case_number'] = merge_info['merge_separator'].join(case_number_parts) if case_number_parts else None
                    else:
                        case_data['case_number'] = self._safe_extract_value(row, column_mapping.get('case_number'))


                    # ğŸ”¥ èª¿è©¦ï¼šé¡¯ç¤ºæå–çš„è³‡æ–™
                    if processed_rows < 3:  # åªé¡¯ç¤ºå‰3ç­†ç”¨æ–¼èª¿è©¦
                        print(f"    ç¬¬ {processed_rows + 1} ç­†è³‡æ–™: ç•¶äº‹äºº='{case_data['client']}', æ¡ˆç”±='{case_data['case_reason']}'")

                    # æª¢æŸ¥å¿…è¦æ¬„ä½
                    if not case_data['client']:  # ç•¶äº‹äººæ˜¯å¿…è¦æ¬„ä½
                        if processed_rows < 3:
                            print(f"      âŒ è·³éï¼šæ²’æœ‰ç•¶äº‹äººè³‡æ–™")
                        processed_rows += 1
                        continue

                     # å»ºç«‹æ¡ˆä»¶ç‰©ä»¶æ™‚ç¢ºä¿åŒ…å«æ‰€æœ‰æ¬„ä½
                    if CASE_MODEL_AVAILABLE:
                        case = CaseData(
                            case_type=case_data['case_type'],
                            client=case_data['client'],
                            case_id=case_data['case_id'],
                            case_reason=case_data['case_reason'],
                            case_number=case_data['case_number'],  # ğŸ”¥ ç¢ºä¿å‚³å…¥ case_number
                            court=case_data['court'],              # ğŸ”¥ ç¢ºä¿å‚³å…¥ court
                            division=case_data['division'],
                            lawyer=case_data['lawyer'],
                            legal_affairs=case_data['legal_affairs'],
                            opposing_party=case_data['opposing_party'],
                            progress='å¾…è™•ç†'
                        )
                    else:
                        case = case_data
                        case['progress'] = 'å¾…è™•ç†'

                    cases.append(case)
                    processed_rows += 1

                except Exception as e:
                    print(f"      è™•ç†ç¬¬ {index + 1} è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue

            return cases

        except Exception as e:
            print(f"âŒ å¾å·¥ä½œè¡¨ {sheet_name} æå–è³‡æ–™å¤±æ•—: {e}")
            return []


    def _safe_extract_value(self, row, column_name: str) -> Optional[str]:
        """
        å®‰å…¨æå–æ¬„ä½å€¼ - ğŸ”¥ ä¿®æ”¹ç‰ˆæœ¬ï¼Œå¢åŠ è³‡æ–™æ¸…ç†
        """
        if not column_name:
            return None

        try:
            value = row.get(column_name, None)
            if pd.isna(value):
                return None

            # ğŸ”¥ æ–°å¢ï¼šä½¿ç”¨çµ±ä¸€çš„è³‡æ–™æ¸…ç†å·¥å…·
            cleaned_value = DataCleaner.clean_text_data(value)
            return cleaned_value

        except Exception as e:
            return None

    def _get_best_engine(self, file_path: str) -> Optional[str]:
        """æ ¹æ“šæª”æ¡ˆæ ¼å¼é¸æ“‡æœ€ä½³å¼•æ“"""
        file_ext = os.path.splitext(file_path)[1].lower()

        if file_ext == '.xlsx':
            if OPENPYXL_AVAILABLE:
                return 'openpyxl'
            elif XLRD_AVAILABLE:
                return 'xlrd'
        elif file_ext == '.xls':
            if XLRD_AVAILABLE:
                return 'xlrd'
            elif OPENPYXL_AVAILABLE:
                return 'openpyxl'

        return None

    def validate_analysis_result(self, analysis_result: Dict[str, Any]) -> Tuple[bool, str]:
        """é©—è­‰åˆ†æçµæœçš„æœ‰æ•ˆæ€§"""
        try:
            if not analysis_result:
                return False, "åˆ†æçµæœç‚ºç©º"

            sheets_analysis = analysis_result.get('sheets_analysis', {})
            if not sheets_analysis:
                return False, "æ²’æœ‰æ‰¾åˆ°å¯è™•ç†çš„å·¥ä½œè¡¨"

            processable_count = 0
            for sheet_name, analysis in sheets_analysis.items():
                if analysis.get('success') and analysis.get('has_client_field'):
                    processable_count += 1

            if processable_count == 0:
                return False, "æ²’æœ‰æ‰¾åˆ°åŒ…å«å¿…è¦æ¬„ä½ï¼ˆç•¶äº‹äººï¼‰çš„å·¥ä½œè¡¨"

            return True, f"é©—è­‰é€šéï¼Œæ‰¾åˆ° {processable_count} å€‹å¯è™•ç†çš„å·¥ä½œè¡¨"

        except Exception as e:
            return False, f"é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

    def get_supported_fields(self) -> Dict[str, List[str]]:
        """å–å¾—æ”¯æ´çš„æ¬„ä½åŠå…¶é—œéµå­—"""
        return self.field_keywords.copy()

    def get_supported_case_types(self) -> Dict[str, List[str]]:
        """å–å¾—æ”¯æ´çš„æ¡ˆä»¶é¡å‹åŠå…¶é—œéµå­—"""
        return self.case_type_keywords.copy()

    def add_field_keyword(self, field: str, keyword: str) -> bool:
        """æ–°å¢æ¬„ä½é—œéµå­—"""
        try:
            if field not in self.field_keywords:
                self.field_keywords[field] = []

            if keyword not in self.field_keywords[field]:
                self.field_keywords[field].append(keyword)
                return True
            return False
        except Exception as e:
            print(f"æ–°å¢æ¬„ä½é—œéµå­—å¤±æ•—: {e}")
            return False

    def add_case_type_keyword(self, case_type: str, keyword: str) -> bool:
        """æ–°å¢æ¡ˆä»¶é¡å‹é—œéµå­—"""
        try:
            if case_type not in self.case_type_keywords:
                self.case_type_keywords[case_type] = []

            if keyword not in self.case_type_keywords[case_type]:
                self.case_type_keywords[case_type].append(keyword)
                return True
            return False
        except Exception as e:
            print(f"æ–°å¢æ¡ˆä»¶é¡å‹é—œéµå­—å¤±æ•—: {e}")
            return False

    def export_configuration(self) -> Dict[str, Any]:
        """åŒ¯å‡ºç•¶å‰é…ç½®"""
        return {
            'field_keywords': self.field_keywords,
            'case_type_keywords': self.case_type_keywords,
            'header_min_score': self.header_min_score,
            'merge_separator': self.merge_separator
        }

    def import_configuration(self, config: Dict[str, Any]) -> bool:
        """åŒ¯å…¥é…ç½®"""
        try:
            if 'field_keywords' in config:
                self.field_keywords = config['field_keywords']

            if 'case_type_keywords' in config:
                self.case_type_keywords = config['case_type_keywords']

            if 'header_min_score' in config:
                self.header_min_score = config['header_min_score']

            if 'merge_separator' in config:
                self.merge_separator = config['merge_separator']

            return True
        except Exception as e:
            print(f"åŒ¯å…¥é…ç½®å¤±æ•—: {e}")
            return False
